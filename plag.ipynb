{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-10T06:09:20.122392Z",
     "start_time": "2025-04-10T06:09:19.044141800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Cell 2: Configure Chrome with options to bypass detection\n",
    "options = Options()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_experimental_option(\"detach\", True)  # Prevents auto-close\n",
    "\n",
    "# Add options to make selenium harder to detect\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "# Start Selenium\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Execute CDP commands to bypass detection\n",
    "driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {\n",
    "            get: () => undefined\n",
    "        })\n",
    "    \"\"\"\n",
    "})\n",
    "\n",
    "# Navigate to HackerRank\n",
    "driver.get(\"https://www.hackerrank.com/dashboard\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T07:24:12.836375200Z",
     "start_time": "2025-04-06T07:24:04.511682800Z"
    }
   },
   "id": "7e8b6bec5199869",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error navigating to Administration page: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF70CF74C25+3179557]\n",
      "\t(No symbol) [0x00007FF70CBD88A0]\n",
      "\t(No symbol) [0x00007FF70CA691CA]\n",
      "\t(No symbol) [0x00007FF70CABFA67]\n",
      "\t(No symbol) [0x00007FF70CABFC9C]\n",
      "\t(No symbol) [0x00007FF70CB13627]\n",
      "\t(No symbol) [0x00007FF70CAE7C6F]\n",
      "\t(No symbol) [0x00007FF70CB102F3]\n",
      "\t(No symbol) [0x00007FF70CAE7A03]\n",
      "\t(No symbol) [0x00007FF70CAB06D0]\n",
      "\t(No symbol) [0x00007FF70CAB1983]\n",
      "\tGetHandleVerifier [0x00007FF70CFD67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF70CFED1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF70CFE2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF70CD4092A+868650]\n",
      "\t(No symbol) [0x00007FF70CBE2FFF]\n",
      "\t(No symbol) [0x00007FF70CBDF4A4]\n",
      "\t(No symbol) [0x00007FF70CBDF646]\n",
      "\t(No symbol) [0x00007FF70CBCEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FFBF2B6E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFBF3BFBF6C+44]\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Navigate to Administration\n",
    "try:\n",
    "    # Navigate to Administration page using the CSS selector\n",
    "    admin_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.profile-nav-item-link[href='/administration/contests']\"))\n",
    "    )\n",
    "    admin_link.click()\n",
    "    print(\"Successfully navigated to Administration page!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error navigating to Administration page: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T07:25:25.367463200Z",
     "start_time": "2025-04-06T07:25:15.169765700Z"
    }
   },
   "id": "e399686aedd4d974",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully selected the contest!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Select specific contest using data-key\n",
    "try:\n",
    "    # Find the contest with the specific data-key\n",
    "    contest_selector = f\"td[data-key='308429.0']\"\n",
    "    \n",
    "    # Wait for the element to be clickable\n",
    "    contest_element = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, contest_selector))\n",
    "    )\n",
    "    \n",
    "    # Click on the row to select the contest\n",
    "    contest_element.click()\n",
    "    print(\"Successfully selected the contest!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error selecting contest: {e}\")\n",
    "    # Take a screenshot to debug\n",
    "    driver.save_screenshot(\"contest_selection_error.png\")\n",
    "    print(\"Screenshot saved as 'contest_selection_error.png'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T07:25:44.772898900Z",
     "start_time": "2025-04-06T07:25:42.772524600Z"
    }
   },
   "id": "6fab2cebc4d284c1",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully clicked on the Statistics button!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 (Alternative): Click on Statistics button using XPath with text\n",
    "try:\n",
    "    # Use XPath to find the element with the exact text \"Statistics\"\n",
    "    statistics_xpath = \"//a[contains(@class, 'cursor') and contains(@class, 'change-tab') and text()='Statistics']\"\n",
    "    \n",
    "    # Wait for the element to be clickable\n",
    "    statistics_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, statistics_xpath))\n",
    "    )\n",
    "    \n",
    "    # Click the Statistics button\n",
    "    statistics_button.click()\n",
    "    print(\"Successfully clicked on the Statistics button!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error clicking Statistics button using XPath: {e}\")\n",
    "    # Take a screenshot to debug\n",
    "    driver.save_screenshot(\"statistics_xpath_error.png\")\n",
    "    print(\"Screenshot saved as 'statistics_xpath_error.png'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T07:26:00.136279Z",
     "start_time": "2025-04-06T07:26:00.052454Z"
    }
   },
   "id": "c9425039e9b2087f",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully navigated to the contest submissions page!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Navigate to contest submissions page\n",
    "try:\n",
    "    # Use the CSS selector for the \"View all contest submissions\" link\n",
    "    submissions_selector = \"a.mlT.btn.btn-green\"\n",
    "    \n",
    "    # Wait for the element to be clickable\n",
    "    submissions_link = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, submissions_selector))\n",
    "    )\n",
    "    \n",
    "    # Click the submissions link\n",
    "    submissions_link.click()\n",
    "    print(\"Successfully navigated to the contest submissions page!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error navigating to submissions page: {e}\")\n",
    "    # Take a screenshot to debug\n",
    "    driver.save_screenshot(\"submissions_click_error.png\")\n",
    "    print(\"Screenshot saved as 'submissions_click_error.png'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T07:26:05.618787200Z",
     "start_time": "2025-04-06T07:26:04.662162300Z"
    }
   },
   "id": "d70fb5066562f54c",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-06 12:56:16] \n",
      "==== Processing Page 1/190 ====\n",
      "[2025-04-06 12:56:19] Found 10 'View' buttons on page 1\n",
      "[2025-04-06 12:56:19] Processing batch 1 of 4\n",
      "[2025-04-06 12:56:20] Opened submission 1/10 (ID: 1390888484)\n",
      "[2025-04-06 12:56:21] Opened submission 2/10 (ID: 1390888164)\n",
      "[2025-04-06 12:56:22] Opened submission 3/10 (ID: 1390888085)\n",
      "[2025-04-06 12:56:27] Successfully extracted submission 1390888484\n",
      "[2025-04-06 12:56:28] Successfully extracted submission 1390888085\n",
      "[2025-04-06 12:56:28] Successfully extracted submission 1390888164\n",
      "[2025-04-06 12:56:31] Processing batch 2 of 4\n",
      "[2025-04-06 12:56:32] Opened submission 4/10 (ID: 1390887811)\n",
      "[2025-04-06 12:56:33] Opened submission 5/10 (ID: 1390887752)\n",
      "[2025-04-06 12:56:34] Opened submission 6/10 (ID: 1390887531)\n",
      "[2025-04-06 12:56:39] Successfully extracted submission 1390887531\n",
      "[2025-04-06 12:56:40] Successfully extracted submission 1390887752\n",
      "[2025-04-06 12:56:40] Successfully extracted submission 1390887811\n",
      "[2025-04-06 12:56:43] Processing batch 3 of 4\n",
      "[2025-04-06 12:56:44] Opened submission 7/10 (ID: 1390887448)\n",
      "[2025-04-06 12:56:45] Opened submission 8/10 (ID: 1390887389)\n",
      "[2025-04-06 12:56:46] Opened submission 9/10 (ID: 1390887378)\n",
      "[2025-04-06 12:56:51] Successfully extracted submission 1390887378\n",
      "[2025-04-06 12:56:51] Successfully extracted submission 1390887389\n",
      "[2025-04-06 12:56:52] Successfully extracted submission 1390887448\n",
      "[2025-04-06 12:56:55] Processing batch 4 of 4\n",
      "[2025-04-06 12:56:56] Opened submission 10/10 (ID: 1390887303)\n",
      "[2025-04-06 12:57:01] Successfully extracted submission 1390887303\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page001.csv\n",
      "[2025-04-06 12:57:04] Saved 10 submissions from page 1\n",
      "[2025-04-06 12:57:04] Waiting 9.0 seconds before navigating to the next page\n",
      "[2025-04-06 12:57:13] Navigating to page 2\n",
      "[2025-04-06 12:57:18] \n",
      "==== Processing Page 2/190 ====\n",
      "[2025-04-06 12:57:21] Found 10 'View' buttons on page 2\n",
      "[2025-04-06 12:57:21] Processing batch 1 of 4\n",
      "[2025-04-06 12:57:22] Opened submission 1/10 (ID: 1390887300)\n",
      "[2025-04-06 12:57:23] Opened submission 2/10 (ID: 1390887282)\n",
      "[2025-04-06 12:57:24] Opened submission 3/10 (ID: 1390887279)\n",
      "[2025-04-06 12:57:30] Successfully extracted submission 1390887282\n",
      "[2025-04-06 12:57:30] Successfully extracted submission 1390887279\n",
      "[2025-04-06 12:57:30] Successfully extracted submission 1390887300\n",
      "[2025-04-06 12:57:33] Processing batch 2 of 4\n",
      "[2025-04-06 12:57:34] Opened submission 4/10 (ID: 1390887272)\n",
      "[2025-04-06 12:57:35] Opened submission 5/10 (ID: 1390887263)\n",
      "[2025-04-06 12:57:36] Opened submission 6/10 (ID: 1390887261)\n",
      "[2025-04-06 12:57:42] Successfully extracted submission 1390887261\n",
      "[2025-04-06 12:57:42] Successfully extracted submission 1390887263\n",
      "[2025-04-06 12:57:42] Successfully extracted submission 1390887272\n",
      "[2025-04-06 12:57:45] Processing batch 3 of 4\n",
      "[2025-04-06 12:57:46] Opened submission 7/10 (ID: 1390887254)\n",
      "[2025-04-06 12:57:47] Opened submission 8/10 (ID: 1390887252)\n",
      "[2025-04-06 12:57:48] Opened submission 9/10 (ID: 1390887237)\n",
      "[2025-04-06 12:57:54] Successfully extracted submission 1390887237\n",
      "[2025-04-06 12:57:54] Successfully extracted submission 1390887252\n",
      "[2025-04-06 12:57:54] Successfully extracted submission 1390887254\n",
      "[2025-04-06 12:57:57] Processing batch 4 of 4\n",
      "[2025-04-06 12:57:59] Opened submission 10/10 (ID: 1390887233)\n",
      "[2025-04-06 12:58:04] Successfully extracted submission 1390887233\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page002.csv\n",
      "[2025-04-06 12:58:07] Saved 10 submissions from page 2\n",
      "[2025-04-06 12:58:07] Waiting 9.5 seconds before navigating to the next page\n",
      "[2025-04-06 12:58:16] Navigating to page 3\n",
      "[2025-04-06 12:58:21] \n",
      "==== Processing Page 3/190 ====\n",
      "[2025-04-06 12:58:24] Found 10 'View' buttons on page 3\n",
      "[2025-04-06 12:58:24] Processing batch 1 of 4\n",
      "[2025-04-06 12:58:25] Opened submission 1/10 (ID: 1390887225)\n",
      "[2025-04-06 12:58:27] Opened submission 2/10 (ID: 1390887223)\n",
      "[2025-04-06 12:58:28] Opened submission 3/10 (ID: 1390887215)\n",
      "[2025-04-06 12:58:33] Successfully extracted submission 1390887215\n",
      "[2025-04-06 12:58:33] Successfully extracted submission 1390887223\n",
      "[2025-04-06 12:58:33] Successfully extracted submission 1390887225\n",
      "[2025-04-06 12:58:36] Processing batch 2 of 4\n",
      "[2025-04-06 12:58:38] Opened submission 4/10 (ID: 1390887200)\n",
      "[2025-04-06 12:58:39] Opened submission 5/10 (ID: 1390887188)\n",
      "[2025-04-06 12:58:40] Opened submission 6/10 (ID: 1390887182)\n",
      "[2025-04-06 12:58:45] Successfully extracted submission 1390887182\n",
      "[2025-04-06 12:58:45] Successfully extracted submission 1390887200\n",
      "[2025-04-06 12:58:46] Successfully extracted submission 1390887188\n",
      "[2025-04-06 12:58:49] Processing batch 3 of 4\n",
      "[2025-04-06 12:58:50] Opened submission 7/10 (ID: 1390887179)\n",
      "[2025-04-06 12:58:51] Opened submission 8/10 (ID: 1390887175)\n",
      "[2025-04-06 12:58:52] Opened submission 9/10 (ID: 1390887172)\n",
      "[2025-04-06 12:58:57] Successfully extracted submission 1390887172\n",
      "[2025-04-06 12:58:57] Successfully extracted submission 1390887175\n",
      "[2025-04-06 12:58:58] Successfully extracted submission 1390887179\n",
      "[2025-04-06 12:59:01] Processing batch 4 of 4\n",
      "[2025-04-06 12:59:02] Opened submission 10/10 (ID: 1390887167)\n",
      "[2025-04-06 12:59:07] Successfully extracted submission 1390887167\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page003.csv\n",
      "[2025-04-06 12:59:10] Saved 10 submissions from page 3\n",
      "[2025-04-06 12:59:10] Waiting 8.9 seconds before navigating to the next page\n",
      "[2025-04-06 12:59:19] Navigating to page 4\n",
      "[2025-04-06 12:59:24] \n",
      "==== Processing Page 4/190 ====\n",
      "[2025-04-06 12:59:27] Found 10 'View' buttons on page 4\n",
      "[2025-04-06 12:59:27] Processing batch 1 of 4\n",
      "[2025-04-06 12:59:28] Opened submission 1/10 (ID: 1390887145)\n",
      "[2025-04-06 12:59:29] Opened submission 2/10 (ID: 1390887141)\n",
      "[2025-04-06 12:59:30] Opened submission 3/10 (ID: 1390887125)\n",
      "[2025-04-06 12:59:35] Successfully extracted submission 1390887141\n",
      "[2025-04-06 12:59:36] Successfully extracted submission 1390887125\n",
      "[2025-04-06 12:59:36] Successfully extracted submission 1390887145\n",
      "[2025-04-06 12:59:39] Processing batch 2 of 4\n",
      "[2025-04-06 12:59:40] Opened submission 4/10 (ID: 1390887122)\n",
      "[2025-04-06 12:59:41] Opened submission 5/10 (ID: 1390887119)\n",
      "[2025-04-06 12:59:42] Opened submission 6/10 (ID: 1390887118)\n",
      "[2025-04-06 12:59:47] Successfully extracted submission 1390887118\n",
      "[2025-04-06 12:59:48] Successfully extracted submission 1390887119\n",
      "[2025-04-06 12:59:48] Successfully extracted submission 1390887122\n",
      "[2025-04-06 12:59:51] Processing batch 3 of 4\n",
      "[2025-04-06 12:59:52] Opened submission 7/10 (ID: 1390887109)\n",
      "[2025-04-06 12:59:53] Opened submission 8/10 (ID: 1390887084)\n",
      "[2025-04-06 12:59:54] Opened submission 9/10 (ID: 1390887083)\n",
      "[2025-04-06 12:59:59] Successfully extracted submission 1390887083\n",
      "[2025-04-06 13:00:00] Successfully extracted submission 1390887109\n",
      "[2025-04-06 13:00:00] Successfully extracted submission 1390887084\n",
      "[2025-04-06 13:00:03] Processing batch 4 of 4\n",
      "[2025-04-06 13:00:04] Opened submission 10/10 (ID: 1390887067)\n",
      "[2025-04-06 13:00:09] Successfully extracted submission 1390887067\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page004.csv\n",
      "[2025-04-06 13:00:12] Saved 10 submissions from page 4\n",
      "[2025-04-06 13:00:12] Waiting 6.5 seconds before navigating to the next page\n",
      "[2025-04-06 13:00:19] Navigating to page 5\n",
      "[2025-04-06 13:00:24] \n",
      "==== Processing Page 5/190 ====\n",
      "[2025-04-06 13:00:27] Found 10 'View' buttons on page 5\n",
      "[2025-04-06 13:00:27] Processing batch 1 of 4\n",
      "[2025-04-06 13:00:28] Opened submission 1/10 (ID: 1390887059)\n",
      "[2025-04-06 13:00:29] Opened submission 2/10 (ID: 1390887053)\n",
      "[2025-04-06 13:00:30] Opened submission 3/10 (ID: 1390887051)\n",
      "[2025-04-06 13:00:35] Successfully extracted submission 1390887051\n",
      "[2025-04-06 13:00:36] Successfully extracted submission 1390887053\n",
      "[2025-04-06 13:00:36] Successfully extracted submission 1390887059\n",
      "[2025-04-06 13:00:39] Processing batch 2 of 4\n",
      "[2025-04-06 13:00:40] Opened submission 4/10 (ID: 1390887048)\n",
      "[2025-04-06 13:00:41] Opened submission 5/10 (ID: 1390887038)\n",
      "[2025-04-06 13:00:42] Opened submission 6/10 (ID: 1390887010)\n",
      "[2025-04-06 13:00:47] Successfully extracted submission 1390887048\n",
      "[2025-04-06 13:00:48] Successfully extracted submission 1390887010\n",
      "[2025-04-06 13:00:48] Successfully extracted submission 1390887038\n",
      "[2025-04-06 13:00:51] Processing batch 3 of 4\n",
      "[2025-04-06 13:00:52] Opened submission 7/10 (ID: 1390887009)\n",
      "[2025-04-06 13:00:53] Opened submission 8/10 (ID: 1390886998)\n",
      "[2025-04-06 13:00:54] Opened submission 9/10 (ID: 1390886963)\n",
      "[2025-04-06 13:00:59] Successfully extracted submission 1390886963\n",
      "[2025-04-06 13:01:00] Successfully extracted submission 1390886998\n",
      "[2025-04-06 13:01:00] Successfully extracted submission 1390887009\n",
      "[2025-04-06 13:01:03] Processing batch 4 of 4\n",
      "[2025-04-06 13:01:04] Opened submission 10/10 (ID: 1390886961)\n",
      "[2025-04-06 13:01:09] Successfully extracted submission 1390886961\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page005.csv\n",
      "[2025-04-06 13:01:12] Saved 10 submissions from page 5\n",
      "[2025-04-06 13:01:12] Waiting 7.6 seconds before navigating to the next page\n",
      "[2025-04-06 13:01:20] Navigating to page 6\n",
      "[2025-04-06 13:01:25] \n",
      "==== Processing Page 6/190 ====\n",
      "[2025-04-06 13:01:28] Found 10 'View' buttons on page 6\n",
      "[2025-04-06 13:01:28] Processing batch 1 of 4\n",
      "[2025-04-06 13:01:29] Opened submission 1/10 (ID: 1390886951)\n",
      "[2025-04-06 13:01:30] Opened submission 2/10 (ID: 1390886949)\n",
      "[2025-04-06 13:01:31] Opened submission 3/10 (ID: 1390886940)\n",
      "[2025-04-06 13:01:37] Successfully extracted submission 1390886949\n",
      "[2025-04-06 13:01:37] Successfully extracted submission 1390886951\n",
      "[2025-04-06 13:01:37] Successfully extracted submission 1390886940\n",
      "[2025-04-06 13:01:40] Processing batch 2 of 4\n",
      "[2025-04-06 13:01:41] Opened submission 4/10 (ID: 1390886939)\n",
      "[2025-04-06 13:01:42] Opened submission 5/10 (ID: 1390886933)\n",
      "[2025-04-06 13:01:43] Opened submission 6/10 (ID: 1390886928)\n",
      "[2025-04-06 13:01:48] Successfully extracted submission 1390886928\n",
      "[2025-04-06 13:01:49] Successfully extracted submission 1390886933\n",
      "[2025-04-06 13:01:49] Successfully extracted submission 1390886939\n",
      "[2025-04-06 13:01:52] Processing batch 3 of 4\n",
      "[2025-04-06 13:01:53] Opened submission 7/10 (ID: 1390886908)\n",
      "[2025-04-06 13:01:54] Opened submission 8/10 (ID: 1390886904)\n",
      "[2025-04-06 13:01:55] Opened submission 9/10 (ID: 1390886898)\n",
      "[2025-04-06 13:04:55] Successfully extracted submission 1390886904\n",
      "[2025-04-06 13:04:55] Successfully extracted submission 1390886908\n",
      "[2025-04-06 13:04:58] Processing batch 4 of 4\n",
      "[2025-04-06 13:04:59] Opened submission 10/10 (ID: 1390886897)\n",
      "[2025-04-06 13:05:04] Successfully extracted submission 1390886897\n",
      "Successfully saved 9 submissions to hackerrank_data\\hackerrank_submissions_page006.csv\n",
      "[2025-04-06 13:05:08] Saved 9 submissions from page 6\n",
      "[2025-04-06 13:05:08] Waiting 7.4 seconds before navigating to the next page\n",
      "[2025-04-06 13:05:15] Navigating to page 7\n",
      "[2025-04-06 13:05:20] \n",
      "==== Processing Page 7/190 ====\n",
      "[2025-04-06 13:05:23] Found 10 'View' buttons on page 7\n",
      "[2025-04-06 13:05:23] Processing batch 1 of 4\n",
      "[2025-04-06 13:05:24] Opened submission 1/10 (ID: 1390886872)\n",
      "[2025-04-06 13:05:25] Opened submission 2/10 (ID: 1390886857)\n",
      "[2025-04-06 13:05:26] Opened submission 3/10 (ID: 1390886854)\n",
      "[2025-04-06 13:05:31] Successfully extracted submission 1390886854\n",
      "[2025-04-06 13:05:32] Successfully extracted submission 1390886872\n",
      "[2025-04-06 13:05:32] Successfully extracted submission 1390886857\n",
      "[2025-04-06 13:05:35] Processing batch 2 of 4\n",
      "[2025-04-06 13:05:36] Opened submission 4/10 (ID: 1390886834)\n",
      "[2025-04-06 13:05:37] Opened submission 5/10 (ID: 1390886830)\n",
      "[2025-04-06 13:05:38] Opened submission 6/10 (ID: 1390886809)\n",
      "[2025-04-06 13:05:43] Successfully extracted submission 1390886809\n",
      "[2025-04-06 13:05:44] Successfully extracted submission 1390886830\n",
      "[2025-04-06 13:05:44] Successfully extracted submission 1390886834\n",
      "[2025-04-06 13:05:47] Processing batch 3 of 4\n",
      "[2025-04-06 13:05:48] Opened submission 7/10 (ID: 1390886804)\n",
      "[2025-04-06 13:05:49] Opened submission 8/10 (ID: 1390886787)\n",
      "[2025-04-06 13:05:50] Opened submission 9/10 (ID: 1390886785)\n",
      "[2025-04-06 13:05:56] Successfully extracted submission 1390886785\n",
      "[2025-04-06 13:05:56] Successfully extracted submission 1390886787\n",
      "[2025-04-06 13:05:56] Successfully extracted submission 1390886804\n",
      "[2025-04-06 13:05:59] Processing batch 4 of 4\n",
      "[2025-04-06 13:06:00] Opened submission 10/10 (ID: 1390886784)\n",
      "[2025-04-06 13:06:06] Successfully extracted submission 1390886784\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page007.csv\n",
      "[2025-04-06 13:06:09] Saved 10 submissions from page 7\n",
      "[2025-04-06 13:06:09] Waiting 6.8 seconds before navigating to the next page\n",
      "[2025-04-06 13:06:15] Navigating to page 8\n",
      "[2025-04-06 13:06:20] \n",
      "==== Processing Page 8/190 ====\n",
      "[2025-04-06 13:06:23] Found 10 'View' buttons on page 8\n",
      "[2025-04-06 13:06:23] Processing batch 1 of 4\n",
      "[2025-04-06 13:06:25] Opened submission 1/10 (ID: 1390886772)\n",
      "[2025-04-06 13:06:26] Opened submission 2/10 (ID: 1390886771)\n",
      "[2025-04-06 13:06:27] Opened submission 3/10 (ID: 1390886768)\n",
      "[2025-04-06 13:06:32] Successfully extracted submission 1390886768\n",
      "[2025-04-06 13:06:32] Successfully extracted submission 1390886771\n",
      "[2025-04-06 13:06:32] Successfully extracted submission 1390886772\n",
      "[2025-04-06 13:06:35] Processing batch 2 of 4\n",
      "[2025-04-06 13:06:36] Opened submission 4/10 (ID: 1390886763)\n",
      "[2025-04-06 13:06:38] Opened submission 5/10 (ID: 1390886761)\n",
      "[2025-04-06 13:06:39] Opened submission 6/10 (ID: 1390886753)\n",
      "[2025-04-06 13:06:44] Successfully extracted submission 1390886753\n",
      "[2025-04-06 13:06:44] Successfully extracted submission 1390886761\n",
      "[2025-04-06 13:06:44] Successfully extracted submission 1390886763\n",
      "[2025-04-06 13:06:47] Processing batch 3 of 4\n",
      "[2025-04-06 13:06:48] Opened submission 7/10 (ID: 1390886733)\n",
      "[2025-04-06 13:06:50] Opened submission 8/10 (ID: 1390886724)\n",
      "[2025-04-06 13:06:51] Opened submission 9/10 (ID: 1390886717)\n",
      "[2025-04-06 13:06:56] Successfully extracted submission 1390886717\n",
      "[2025-04-06 13:07:16] Error processing submission: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF70CF74C25+3179557]\n",
      "\t(No symbol) [0x00007FF70CBD88A0]\n",
      "\t(No symbol) [0x00007FF70CA691CA]\n",
      "\t(No symbol) [0x00007FF70CABFA67]\n",
      "\t(No symbol) [0x00007FF70CABFC9C]\n",
      "\t(No symbol) [0x00007FF70CB13627]\n",
      "\t(No symbol) [0x00007FF70CAE7C6F]\n",
      "\t(No symbol) [0x00007FF70CB102F3]\n",
      "\t(No symbol) [0x00007FF70CAE7A03]\n",
      "\t(No symbol) [0x00007FF70CAB06D0]\n",
      "\t(No symbol) [0x00007FF70CAB1983]\n",
      "\tGetHandleVerifier [0x00007FF70CFD67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF70CFED1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF70CFE2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF70CD4092A+868650]\n",
      "\t(No symbol) [0x00007FF70CBE2FFF]\n",
      "\t(No symbol) [0x00007FF70CBDF4A4]\n",
      "\t(No symbol) [0x00007FF70CBDF646]\n",
      "\t(No symbol) [0x00007FF70CBCEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FFBF2B6E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFBF3BFBF6C+44]\n",
      "[2025-04-06 13:07:36] Error processing submission: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF70CF74C25+3179557]\n",
      "\t(No symbol) [0x00007FF70CBD88A0]\n",
      "\t(No symbol) [0x00007FF70CA691CA]\n",
      "\t(No symbol) [0x00007FF70CABFA67]\n",
      "\t(No symbol) [0x00007FF70CABFC9C]\n",
      "\t(No symbol) [0x00007FF70CB13627]\n",
      "\t(No symbol) [0x00007FF70CAE7C6F]\n",
      "\t(No symbol) [0x00007FF70CB102F3]\n",
      "\t(No symbol) [0x00007FF70CAE7A03]\n",
      "\t(No symbol) [0x00007FF70CAB06D0]\n",
      "\t(No symbol) [0x00007FF70CAB1983]\n",
      "\tGetHandleVerifier [0x00007FF70CFD67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF70CFED1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF70CFE2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF70CD4092A+868650]\n",
      "\t(No symbol) [0x00007FF70CBE2FFF]\n",
      "\t(No symbol) [0x00007FF70CBDF4A4]\n",
      "\t(No symbol) [0x00007FF70CBDF646]\n",
      "\t(No symbol) [0x00007FF70CBCEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FFBF2B6E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFBF3BFBF6C+44]\n",
      "[2025-04-06 13:07:40] Processing batch 4 of 4\n",
      "[2025-04-06 13:07:41] Opened submission 10/10 (ID: 1390886716)\n",
      "[2025-04-06 13:07:46] Successfully extracted submission 1390886716\n",
      "Successfully saved 8 submissions to hackerrank_data\\hackerrank_submissions_page008.csv\n",
      "[2025-04-06 13:07:49] Saved 8 submissions from page 8\n",
      "[2025-04-06 13:07:49] Waiting 9.9 seconds before navigating to the next page\n",
      "[2025-04-06 13:07:59] Navigating to page 9\n",
      "[2025-04-06 13:08:04] \n",
      "==== Processing Page 9/190 ====\n",
      "[2025-04-06 13:08:07] Found 10 'View' buttons on page 9\n",
      "[2025-04-06 13:08:07] Processing batch 1 of 4\n",
      "[2025-04-06 13:08:08] Opened submission 1/10 (ID: 1390886709)\n",
      "[2025-04-06 13:08:09] Opened submission 2/10 (ID: 1390886694)\n",
      "[2025-04-06 13:08:10] Opened submission 3/10 (ID: 1390886684)\n",
      "[2025-04-06 13:08:15] Successfully extracted submission 1390886684\n",
      "[2025-04-06 13:08:15] Successfully extracted submission 1390886694\n",
      "[2025-04-06 13:08:16] Successfully extracted submission 1390886709\n",
      "[2025-04-06 13:08:19] Processing batch 2 of 4\n",
      "[2025-04-06 13:08:20] Opened submission 4/10 (ID: 1390886683)\n",
      "[2025-04-06 13:08:21] Opened submission 5/10 (ID: 1390886682)\n",
      "[2025-04-06 13:08:22] Opened submission 6/10 (ID: 1390886676)\n",
      "[2025-04-06 13:08:27] Successfully extracted submission 1390886676\n",
      "[2025-04-06 13:08:27] Successfully extracted submission 1390886682\n",
      "[2025-04-06 13:08:27] Successfully extracted submission 1390886683\n",
      "[2025-04-06 13:08:31] Processing batch 3 of 4\n",
      "[2025-04-06 13:08:32] Opened submission 7/10 (ID: 1390886669)\n",
      "[2025-04-06 13:08:33] Opened submission 8/10 (ID: 1390886665)\n",
      "[2025-04-06 13:08:34] Opened submission 9/10 (ID: 1390886656)\n",
      "[2025-04-06 13:08:39] Successfully extracted submission 1390886669\n",
      "[2025-04-06 13:08:39] Successfully extracted submission 1390886656\n",
      "[2025-04-06 13:08:39] Successfully extracted submission 1390886665\n",
      "[2025-04-06 13:08:42] Processing batch 4 of 4\n",
      "[2025-04-06 13:08:43] Opened submission 10/10 (ID: 1390886643)\n",
      "[2025-04-06 13:08:49] Successfully extracted submission 1390886643\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page009.csv\n",
      "[2025-04-06 13:08:52] Saved 10 submissions from page 9\n",
      "[2025-04-06 13:08:52] Waiting 6.5 seconds before navigating to the next page\n",
      "[2025-04-06 13:08:58] Navigating to page 10\n",
      "[2025-04-06 13:09:03] \n",
      "==== Processing Page 10/190 ====\n",
      "[2025-04-06 13:09:06] Found 10 'View' buttons on page 10\n",
      "[2025-04-06 13:09:06] Processing batch 1 of 4\n",
      "[2025-04-06 13:09:07] Opened submission 1/10 (ID: 1390886617)\n",
      "[2025-04-06 13:09:08] Opened submission 2/10 (ID: 1390886613)\n",
      "[2025-04-06 13:09:09] Opened submission 3/10 (ID: 1390886587)\n",
      "[2025-04-06 13:09:14] Successfully extracted submission 1390886587\n",
      "[2025-04-06 13:09:15] Successfully extracted submission 1390886613\n",
      "[2025-04-06 13:09:15] Successfully extracted submission 1390886617\n",
      "[2025-04-06 13:09:18] Processing batch 2 of 4\n",
      "[2025-04-06 13:09:19] Opened submission 4/10 (ID: 1390886579)\n",
      "[2025-04-06 13:09:20] Opened submission 5/10 (ID: 1390886572)\n",
      "[2025-04-06 13:09:21] Opened submission 6/10 (ID: 1390886571)\n",
      "[2025-04-06 13:09:26] Successfully extracted submission 1390886571\n",
      "[2025-04-06 13:09:27] Successfully extracted submission 1390886572\n",
      "[2025-04-06 13:09:27] Successfully extracted submission 1390886579\n",
      "[2025-04-06 13:09:30] Processing batch 3 of 4\n",
      "[2025-04-06 13:09:31] Opened submission 7/10 (ID: 1390886553)\n",
      "[2025-04-06 13:09:32] Opened submission 8/10 (ID: 1390886552)\n",
      "[2025-04-06 13:09:33] Opened submission 9/10 (ID: 1390886547)\n",
      "[2025-04-06 13:09:38] Successfully extracted submission 1390886552\n",
      "[2025-04-06 13:09:39] Successfully extracted submission 1390886553\n",
      "[2025-04-06 13:09:39] Successfully extracted submission 1390886547\n",
      "[2025-04-06 13:09:42] Processing batch 4 of 4\n",
      "[2025-04-06 13:09:43] Opened submission 10/10 (ID: 1390886544)\n",
      "[2025-04-06 13:09:48] Successfully extracted submission 1390886544\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page010.csv\n",
      "[2025-04-06 13:09:51] Saved 10 submissions from page 10\n",
      "[2025-04-06 13:09:51] Waiting 9.3 seconds before navigating to the next page\n",
      "[2025-04-06 13:10:01] Navigating to page 11\n",
      "[2025-04-06 13:10:06] \n",
      "==== Processing Page 11/190 ====\n",
      "[2025-04-06 13:10:09] Found 10 'View' buttons on page 11\n",
      "[2025-04-06 13:10:09] Processing batch 1 of 4\n",
      "[2025-04-06 13:10:10] Opened submission 1/10 (ID: 1390886525)\n",
      "[2025-04-06 13:10:11] Opened submission 2/10 (ID: 1390886519)\n",
      "[2025-04-06 13:10:12] Opened submission 3/10 (ID: 1390886507)\n",
      "[2025-04-06 13:10:17] Successfully extracted submission 1390886519\n",
      "[2025-04-06 13:10:17] Successfully extracted submission 1390886507\n",
      "[2025-04-06 13:10:17] Successfully extracted submission 1390886525\n",
      "[2025-04-06 13:10:21] Processing batch 2 of 4\n",
      "[2025-04-06 13:10:22] Opened submission 4/10 (ID: 1390886504)\n",
      "[2025-04-06 13:10:23] Opened submission 5/10 (ID: 1390886492)\n",
      "[2025-04-06 13:10:24] Opened submission 6/10 (ID: 1390886490)\n",
      "[2025-04-06 13:10:29] Successfully extracted submission 1390886490\n",
      "[2025-04-06 13:10:29] Successfully extracted submission 1390886492\n",
      "[2025-04-06 13:10:29] Successfully extracted submission 1390886504\n",
      "[2025-04-06 13:10:32] Processing batch 3 of 4\n",
      "[2025-04-06 13:10:34] Opened submission 7/10 (ID: 1390886476)\n",
      "[2025-04-06 13:10:35] Opened submission 8/10 (ID: 1390886474)\n",
      "[2025-04-06 13:10:36] Opened submission 9/10 (ID: 1390886473)\n",
      "[2025-04-06 13:10:41] Successfully extracted submission 1390886473\n",
      "[2025-04-06 13:10:41] Successfully extracted submission 1390886476\n",
      "[2025-04-06 13:10:41] Successfully extracted submission 1390886474\n",
      "[2025-04-06 13:10:44] Processing batch 4 of 4\n",
      "[2025-04-06 13:10:45] Opened submission 10/10 (ID: 1390886472)\n",
      "[2025-04-06 13:10:50] Successfully extracted submission 1390886472\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page011.csv\n",
      "[2025-04-06 13:10:54] Saved 10 submissions from page 11\n",
      "[2025-04-06 13:10:54] Waiting 7.0 seconds before navigating to the next page\n",
      "[2025-04-06 13:11:01] Navigating to page 12\n",
      "[2025-04-06 13:11:06] \n",
      "==== Processing Page 12/190 ====\n",
      "[2025-04-06 13:11:09] Found 10 'View' buttons on page 12\n",
      "[2025-04-06 13:11:09] Processing batch 1 of 4\n",
      "[2025-04-06 13:11:10] Opened submission 1/10 (ID: 1390886470)\n",
      "[2025-04-06 13:11:11] Opened submission 2/10 (ID: 1390886453)\n",
      "[2025-04-06 13:11:12] Opened submission 3/10 (ID: 1390886448)\n",
      "[2025-04-06 13:11:17] Successfully extracted submission 1390886448\n",
      "[2025-04-06 13:11:17] Successfully extracted submission 1390886453\n",
      "[2025-04-06 13:11:17] Successfully extracted submission 1390886470\n",
      "[2025-04-06 13:11:20] Processing batch 2 of 4\n",
      "[2025-04-06 13:11:21] Opened submission 4/10 (ID: 1390886433)\n",
      "[2025-04-06 13:11:23] Opened submission 5/10 (ID: 1390886410)\n",
      "[2025-04-06 13:11:24] Opened submission 6/10 (ID: 1390886392)\n",
      "[2025-04-06 13:11:29] Successfully extracted submission 1390886410\n",
      "[2025-04-06 13:11:29] Successfully extracted submission 1390886433\n",
      "[2025-04-06 13:11:29] Successfully extracted submission 1390886392\n",
      "[2025-04-06 13:11:32] Processing batch 3 of 4\n",
      "[2025-04-06 13:11:34] Opened submission 7/10 (ID: 1390886382)\n",
      "[2025-04-06 13:11:35] Opened submission 8/10 (ID: 1390886379)\n",
      "[2025-04-06 13:11:36] Opened submission 9/10 (ID: 1390886358)\n",
      "[2025-04-06 13:11:41] Successfully extracted submission 1390886358\n",
      "[2025-04-06 13:11:41] Successfully extracted submission 1390886379\n",
      "[2025-04-06 13:11:41] Successfully extracted submission 1390886382\n",
      "[2025-04-06 13:11:44] Processing batch 4 of 4\n",
      "[2025-04-06 13:11:45] Opened submission 10/10 (ID: 1390886345)\n",
      "[2025-04-06 13:11:51] Successfully extracted submission 1390886345\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page012.csv\n",
      "[2025-04-06 13:11:54] Saved 10 submissions from page 12\n",
      "[2025-04-06 13:11:54] Waiting 6.3 seconds before navigating to the next page\n",
      "[2025-04-06 13:12:00] Navigating to page 13\n",
      "[2025-04-06 13:12:05] \n",
      "==== Processing Page 13/190 ====\n",
      "[2025-04-06 13:12:08] Found 10 'View' buttons on page 13\n",
      "[2025-04-06 13:12:08] Processing batch 1 of 4\n",
      "[2025-04-06 13:12:09] Opened submission 1/10 (ID: 1390886327)\n",
      "[2025-04-06 13:12:10] Opened submission 2/10 (ID: 1390886299)\n",
      "[2025-04-06 13:12:11] Opened submission 3/10 (ID: 1390886287)\n",
      "[2025-04-06 13:12:16] Successfully extracted submission 1390886287\n",
      "[2025-04-06 13:12:16] Successfully extracted submission 1390886299\n",
      "[2025-04-06 13:12:17] Successfully extracted submission 1390886327\n",
      "[2025-04-06 13:12:20] Processing batch 2 of 4\n",
      "[2025-04-06 13:12:21] Opened submission 4/10 (ID: 1390886285)\n",
      "[2025-04-06 13:12:22] Opened submission 5/10 (ID: 1390886279)\n",
      "[2025-04-06 13:12:23] Opened submission 6/10 (ID: 1390886271)\n",
      "[2025-04-06 13:12:28] Successfully extracted submission 1390886279\n",
      "[2025-04-06 13:12:28] Successfully extracted submission 1390886271\n",
      "[2025-04-06 13:12:29] Successfully extracted submission 1390886285\n",
      "[2025-04-06 13:12:32] Processing batch 3 of 4\n",
      "[2025-04-06 13:12:33] Opened submission 7/10 (ID: 1390886269)\n",
      "[2025-04-06 13:12:34] Opened submission 8/10 (ID: 1390886248)\n",
      "[2025-04-06 13:12:35] Opened submission 9/10 (ID: 1390886238)\n",
      "[2025-04-06 13:12:40] Successfully extracted submission 1390886238\n",
      "[2025-04-06 13:12:40] Successfully extracted submission 1390886248\n",
      "[2025-04-06 13:12:40] Successfully extracted submission 1390886269\n",
      "[2025-04-06 13:12:44] Processing batch 4 of 4\n",
      "[2025-04-06 13:12:45] Opened submission 10/10 (ID: 1390886221)\n",
      "[2025-04-06 13:12:50] Successfully extracted submission 1390886221\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page013.csv\n",
      "[2025-04-06 13:12:53] Saved 10 submissions from page 13\n",
      "[2025-04-06 13:12:53] Waiting 6.4 seconds before navigating to the next page\n",
      "[2025-04-06 13:12:59] Navigating to page 14\n",
      "[2025-04-06 13:13:04] \n",
      "==== Processing Page 14/190 ====\n",
      "[2025-04-06 13:13:07] Found 10 'View' buttons on page 14\n",
      "[2025-04-06 13:13:07] Processing batch 1 of 4\n",
      "[2025-04-06 13:13:08] Opened submission 1/10 (ID: 1390886211)\n",
      "[2025-04-06 13:13:09] Opened submission 2/10 (ID: 1390886207)\n",
      "[2025-04-06 13:13:10] Opened submission 3/10 (ID: 1390886202)\n",
      "[2025-04-06 13:13:16] Successfully extracted submission 1390886202\n",
      "[2025-04-06 13:13:16] Successfully extracted submission 1390886207\n",
      "[2025-04-06 13:13:16] Successfully extracted submission 1390886211\n",
      "[2025-04-06 13:13:19] Processing batch 2 of 4\n",
      "[2025-04-06 13:13:20] Opened submission 4/10 (ID: 1390886187)\n",
      "[2025-04-06 13:13:21] Opened submission 5/10 (ID: 1390886181)\n",
      "[2025-04-06 13:13:22] Opened submission 6/10 (ID: 1390886179)\n",
      "[2025-04-06 13:13:28] Successfully extracted submission 1390886179\n",
      "[2025-04-06 13:13:28] Successfully extracted submission 1390886181\n",
      "[2025-04-06 13:13:28] Successfully extracted submission 1390886187\n",
      "[2025-04-06 13:13:31] Processing batch 3 of 4\n",
      "[2025-04-06 13:13:32] Opened submission 7/10 (ID: 1390886156)\n",
      "[2025-04-06 13:13:33] Opened submission 8/10 (ID: 1390886147)\n",
      "[2025-04-06 13:13:34] Opened submission 9/10 (ID: 1390886142)\n",
      "[2025-04-06 13:13:40] Successfully extracted submission 1390886142\n",
      "[2025-04-06 13:13:40] Successfully extracted submission 1390886147\n",
      "[2025-04-06 13:13:40] Successfully extracted submission 1390886156\n",
      "[2025-04-06 13:13:43] Processing batch 4 of 4\n",
      "[2025-04-06 13:13:44] Opened submission 10/10 (ID: 1390886127)\n",
      "[2025-04-06 13:13:49] Successfully extracted submission 1390886127\n",
      "Successfully saved 10 submissions to hackerrank_data\\hackerrank_submissions_page014.csv\n",
      "[2025-04-06 13:13:52] Saved 10 submissions from page 14\n",
      "[2025-04-06 13:13:52] Waiting 5.9 seconds before navigating to the next page\n",
      "[2025-04-06 13:13:58] Navigating to page 15\n",
      "[2025-04-06 13:14:03] \n",
      "==== Processing Page 15/190 ====\n",
      "[2025-04-06 13:14:06] Found 6 'View' buttons on page 15\n",
      "[2025-04-06 13:14:06] Processing batch 1 of 2\n",
      "[2025-04-06 13:14:07] Opened submission 1/6 (ID: 1390886099)\n",
      "[2025-04-06 13:14:08] Opened submission 2/6 (ID: 1390886096)\n",
      "[2025-04-06 13:14:09] Opened submission 3/6 (ID: 1390886070)\n",
      "[2025-04-06 13:14:15] Successfully extracted submission 1390886070\n",
      "[2025-04-06 13:14:15] Successfully extracted submission 1390886096\n",
      "[2025-04-06 13:14:15] Successfully extracted submission 1390886099\n",
      "[2025-04-06 13:14:18] Processing batch 2 of 2\n",
      "[2025-04-06 13:14:19] Opened submission 4/6 (ID: 1390886044)\n",
      "[2025-04-06 13:14:20] Opened submission 5/6 (ID: 1390886038)\n",
      "[2025-04-06 13:14:21] Opened submission 6/6 (ID: 1390886020)\n",
      "[2025-04-06 13:14:26] Successfully extracted submission 1390886020\n",
      "[2025-04-06 13:14:27] Successfully extracted submission 1390886044\n",
      "[2025-04-06 13:14:27] Successfully extracted submission 1390886038\n",
      "Successfully saved 6 submissions to hackerrank_data\\hackerrank_submissions_page015.csv\n",
      "[2025-04-06 13:14:30] Saved 6 submissions from page 15\n",
      "[2025-04-06 13:14:30] Waiting 6.5 seconds before navigating to the next page\n",
      "[2025-04-06 13:14:47] Error navigating to next page: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF70CF74C25+3179557]\n",
      "\t(No symbol) [0x00007FF70CBD88A0]\n",
      "\t(No symbol) [0x00007FF70CA691CA]\n",
      "\t(No symbol) [0x00007FF70CABFA67]\n",
      "\t(No symbol) [0x00007FF70CABFC9C]\n",
      "\t(No symbol) [0x00007FF70CB13627]\n",
      "\t(No symbol) [0x00007FF70CAE7C6F]\n",
      "\t(No symbol) [0x00007FF70CB102F3]\n",
      "\t(No symbol) [0x00007FF70CAE7A03]\n",
      "\t(No symbol) [0x00007FF70CAB06D0]\n",
      "\t(No symbol) [0x00007FF70CAB1983]\n",
      "\tGetHandleVerifier [0x00007FF70CFD67CD+3579853]\n",
      "\tGetHandleVerifier [0x00007FF70CFED1D2+3672530]\n",
      "\tGetHandleVerifier [0x00007FF70CFE2153+3627347]\n",
      "\tGetHandleVerifier [0x00007FF70CD4092A+868650]\n",
      "\t(No symbol) [0x00007FF70CBE2FFF]\n",
      "\t(No symbol) [0x00007FF70CBDF4A4]\n",
      "\t(No symbol) [0x00007FF70CBDF646]\n",
      "\t(No symbol) [0x00007FF70CBCEAA9]\n",
      "\tBaseThreadInitThunk [0x00007FFBF2B6E8D7+23]\n",
      "\tRtlUserThreadStart [0x00007FFBF3BFBF6C+44]\n",
      "\n",
      "Added data from hackerrank_submissions_page001.csv\n",
      "Added data from hackerrank_submissions_page002.csv\n",
      "Added data from hackerrank_submissions_page003.csv\n",
      "Added data from hackerrank_submissions_page004.csv\n",
      "Added data from hackerrank_submissions_page005.csv\n",
      "Added data from hackerrank_submissions_page006.csv\n",
      "Added data from hackerrank_submissions_page007.csv\n",
      "Added data from hackerrank_submissions_page008.csv\n",
      "Added data from hackerrank_submissions_page009.csv\n",
      "Added data from hackerrank_submissions_page010.csv\n",
      "Added data from hackerrank_submissions_page011.csv\n",
      "Added data from hackerrank_submissions_page012.csv\n",
      "Added data from hackerrank_submissions_page013.csv\n",
      "Added data from hackerrank_submissions_page014.csv\n",
      "Added data from hackerrank_submissions_page015.csv\n",
      "Added data from hackerrank_submissions_page016.csv\n",
      "Added data from hackerrank_submissions_page017.csv\n",
      "Added data from hackerrank_submissions_page018.csv\n",
      "Added data from hackerrank_submissions_page019.csv\n",
      "Added data from hackerrank_submissions_page020.csv\n",
      "Added data from hackerrank_submissions_page021.csv\n",
      "Added data from hackerrank_submissions_page022.csv\n",
      "Added data from hackerrank_submissions_page023.csv\n",
      "Added data from hackerrank_submissions_page024.csv\n",
      "Added data from hackerrank_submissions_page025.csv\n",
      "Added data from hackerrank_submissions_page026.csv\n",
      "Added data from hackerrank_submissions_page027.csv\n",
      "Added data from hackerrank_submissions_page028.csv\n",
      "Added data from hackerrank_submissions_page029.csv\n",
      "Added data from hackerrank_submissions_page030.csv\n",
      "Added data from hackerrank_submissions_page031.csv\n",
      "Added data from hackerrank_submissions_page032.csv\n",
      "Added data from hackerrank_submissions_page033.csv\n",
      "Added data from hackerrank_submissions_page034.csv\n",
      "Added data from hackerrank_submissions_page035.csv\n",
      "Added data from hackerrank_submissions_page036.csv\n",
      "Added data from hackerrank_submissions_page037.csv\n",
      "Added data from hackerrank_submissions_page038.csv\n",
      "Added data from hackerrank_submissions_page039.csv\n",
      "Added data from hackerrank_submissions_page040.csv\n",
      "Added data from hackerrank_submissions_page041.csv\n",
      "Added data from hackerrank_submissions_page042.csv\n",
      "Added data from hackerrank_submissions_page043.csv\n",
      "Added data from hackerrank_submissions_page044.csv\n",
      "Added data from hackerrank_submissions_page045.csv\n",
      "Added data from hackerrank_submissions_page046.csv\n",
      "Added data from hackerrank_submissions_page047.csv\n",
      "Added data from hackerrank_submissions_page048.csv\n",
      "Added data from hackerrank_submissions_page049.csv\n",
      "Added data from hackerrank_submissions_page050.csv\n",
      "Added data from hackerrank_submissions_page051.csv\n",
      "Added data from hackerrank_submissions_page052.csv\n",
      "Added data from hackerrank_submissions_page053.csv\n",
      "Added data from hackerrank_submissions_page054.csv\n",
      "Added data from hackerrank_submissions_page055.csv\n",
      "Added data from hackerrank_submissions_page056.csv\n",
      "Added data from hackerrank_submissions_page057.csv\n",
      "Added data from hackerrank_submissions_page058.csv\n",
      "Added data from hackerrank_submissions_page059.csv\n",
      "Added data from hackerrank_submissions_page060.csv\n",
      "Added data from hackerrank_submissions_page061.csv\n",
      "Added data from hackerrank_submissions_page062.csv\n",
      "Added data from hackerrank_submissions_page063.csv\n",
      "Added data from hackerrank_submissions_page064.csv\n",
      "Added data from hackerrank_submissions_page065.csv\n",
      "Added data from hackerrank_submissions_page066.csv\n",
      "Added data from hackerrank_submissions_page067.csv\n",
      "Added data from hackerrank_submissions_page068.csv\n",
      "Added data from hackerrank_submissions_page069.csv\n",
      "Added data from hackerrank_submissions_page070.csv\n",
      "Added data from hackerrank_submissions_page071.csv\n",
      "Added data from hackerrank_submissions_page072.csv\n",
      "Added data from hackerrank_submissions_page073.csv\n",
      "Added data from hackerrank_submissions_page074.csv\n",
      "Added data from hackerrank_submissions_page075.csv\n",
      "Added data from hackerrank_submissions_page076.csv\n",
      "Added data from hackerrank_submissions_page077.csv\n",
      "Added data from hackerrank_submissions_page078.csv\n",
      "Added data from hackerrank_submissions_page079.csv\n",
      "Added data from hackerrank_submissions_page080.csv\n",
      "Added data from hackerrank_submissions_page081.csv\n",
      "Added data from hackerrank_submissions_page082.csv\n",
      "Added data from hackerrank_submissions_page083.csv\n",
      "Added data from hackerrank_submissions_page084.csv\n",
      "Added data from hackerrank_submissions_page085.csv\n",
      "Added data from hackerrank_submissions_page086.csv\n",
      "Added data from hackerrank_submissions_page087.csv\n",
      "Added data from hackerrank_submissions_page088.csv\n",
      "Added data from hackerrank_submissions_page089.csv\n",
      "Added data from hackerrank_submissions_page090.csv\n",
      "Added data from hackerrank_submissions_page091.csv\n",
      "Added data from hackerrank_submissions_page092.csv\n",
      "Added data from hackerrank_submissions_page093.csv\n",
      "Added data from hackerrank_submissions_page094.csv\n",
      "Added data from hackerrank_submissions_page095.csv\n",
      "Added data from hackerrank_submissions_page096.csv\n",
      "Added data from hackerrank_submissions_page097.csv\n",
      "Added data from hackerrank_submissions_page098.csv\n",
      "Added data from hackerrank_submissions_page099.csv\n",
      "Added data from hackerrank_submissions_page100.csv\n",
      "Added data from hackerrank_submissions_page101.csv\n",
      "Added data from hackerrank_submissions_page102.csv\n",
      "Added data from hackerrank_submissions_page103.csv\n",
      "Added data from hackerrank_submissions_page104.csv\n",
      "Added data from hackerrank_submissions_page105.csv\n",
      "Added data from hackerrank_submissions_page106.csv\n",
      "Added data from hackerrank_submissions_page107.csv\n",
      "Added data from hackerrank_submissions_page108.csv\n",
      "Added data from hackerrank_submissions_page109.csv\n",
      "Added data from hackerrank_submissions_page110.csv\n",
      "Added data from hackerrank_submissions_page111.csv\n",
      "Added data from hackerrank_submissions_page112.csv\n",
      "Added data from hackerrank_submissions_page113.csv\n",
      "Added data from hackerrank_submissions_page114.csv\n",
      "Added data from hackerrank_submissions_page115.csv\n",
      "Added data from hackerrank_submissions_page116.csv\n",
      "Added data from hackerrank_submissions_page117.csv\n",
      "Added data from hackerrank_submissions_page118.csv\n",
      "Added data from hackerrank_submissions_page119.csv\n",
      "Added data from hackerrank_submissions_page120.csv\n",
      "Added data from hackerrank_submissions_page121.csv\n",
      "Added data from hackerrank_submissions_page122.csv\n",
      "Added data from hackerrank_submissions_page123.csv\n",
      "Added data from hackerrank_submissions_page124.csv\n",
      "Added data from hackerrank_submissions_page125.csv\n",
      "Added data from hackerrank_submissions_page126.csv\n",
      "Added data from hackerrank_submissions_page127.csv\n",
      "Added data from hackerrank_submissions_page128.csv\n",
      "Added data from hackerrank_submissions_page129.csv\n",
      "Added data from hackerrank_submissions_page130.csv\n",
      "Added data from hackerrank_submissions_page131.csv\n",
      "Added data from hackerrank_submissions_page132.csv\n",
      "Added data from hackerrank_submissions_page133.csv\n",
      "Added data from hackerrank_submissions_page134.csv\n",
      "Added data from hackerrank_submissions_page135.csv\n",
      "Added data from hackerrank_submissions_page136.csv\n",
      "Added data from hackerrank_submissions_page137.csv\n",
      "Added data from hackerrank_submissions_page138.csv\n",
      "Added data from hackerrank_submissions_page139.csv\n",
      "Added data from hackerrank_submissions_page140.csv\n",
      "Added data from hackerrank_submissions_page141.csv\n",
      "Added data from hackerrank_submissions_page142.csv\n",
      "Added data from hackerrank_submissions_page143.csv\n",
      "Added data from hackerrank_submissions_page144.csv\n",
      "Added data from hackerrank_submissions_page145.csv\n",
      "Added data from hackerrank_submissions_page146.csv\n",
      "Added data from hackerrank_submissions_page147.csv\n",
      "Added data from hackerrank_submissions_page148.csv\n",
      "Added data from hackerrank_submissions_page149.csv\n",
      "Added data from hackerrank_submissions_page150.csv\n",
      "Added data from hackerrank_submissions_page151.csv\n",
      "Added data from hackerrank_submissions_page152.csv\n",
      "Added data from hackerrank_submissions_page153.csv\n",
      "Added data from hackerrank_submissions_page154.csv\n",
      "Added data from hackerrank_submissions_page155.csv\n",
      "Added data from hackerrank_submissions_page156.csv\n",
      "Added data from hackerrank_submissions_page157.csv\n",
      "Added data from hackerrank_submissions_page158.csv\n",
      "Added data from hackerrank_submissions_page159.csv\n",
      "Added data from hackerrank_submissions_page160.csv\n",
      "Added data from hackerrank_submissions_page161.csv\n",
      "Added data from hackerrank_submissions_page162.csv\n",
      "Added data from hackerrank_submissions_page163.csv\n",
      "Added data from hackerrank_submissions_page164.csv\n",
      "Added data from hackerrank_submissions_page165.csv\n",
      "Added data from hackerrank_submissions_page166.csv\n",
      "Added data from hackerrank_submissions_page167.csv\n",
      "Added data from hackerrank_submissions_page168.csv\n",
      "Added data from hackerrank_submissions_page169.csv\n",
      "Added data from hackerrank_submissions_page170.csv\n",
      "Added data from hackerrank_submissions_page171.csv\n",
      "Added data from hackerrank_submissions_page172.csv\n",
      "Added data from hackerrank_submissions_page173.csv\n",
      "Added data from hackerrank_submissions_page174.csv\n",
      "Added data from hackerrank_submissions_page175.csv\n",
      "Added data from hackerrank_submissions_page176.csv\n",
      "Added data from hackerrank_submissions_page177.csv\n",
      "Added data from hackerrank_submissions_page178.csv\n",
      "Added data from hackerrank_submissions_page179.csv\n",
      "Added data from hackerrank_submissions_page180.csv\n",
      "Added data from hackerrank_submissions_page181.csv\n",
      "Added data from hackerrank_submissions_page182.csv\n",
      "Added data from hackerrank_submissions_page183.csv\n",
      "Added data from hackerrank_submissions_page184.csv\n",
      "Added data from hackerrank_submissions_page185.csv\n",
      "Added data from hackerrank_submissions_page186.csv\n",
      "Added data from hackerrank_submissions_page187.csv\n",
      "Added data from hackerrank_submissions_page188.csv\n",
      "Added data from hackerrank_submissions_page189.csv\n",
      "Successfully combined 189 files into all_submissions.csv with 1826 total submissions\n",
      "[2025-04-06 13:14:48] Scraping complete! Total submissions scraped: 143\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "def scrape_hackerrank_with_pagination(driver, max_pages=190, batch_size=3, \n",
    "                                     output_dir=\"hackerrank_data\", \n",
    "                                     wait_between_pages=(5, 10)):\n",
    "    \"\"\"\n",
    "    Scrape HackerRank submissions with pagination, carefully managing resources\n",
    "    \n",
    "    Args:\n",
    "        driver: Selenium WebDriver instance (already on the submissions page)\n",
    "        max_pages: Maximum number of pages to scrape (default 190)\n",
    "        batch_size: Number of submissions to open at once (default 3)\n",
    "        output_dir: Directory to save output files\n",
    "        wait_between_pages: Random wait range between pages (min, max) in seconds\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Create a log file\n",
    "    log_file = os.path.join(output_dir, f\"scrape_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
    "    \n",
    "    def log_message(message):\n",
    "        \"\"\"Write message to log file and print to console\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_entry = f\"[{timestamp}] {message}\"\n",
    "        print(log_entry)\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(log_entry + \"\\n\")\n",
    "    \n",
    "    # Initialize count of total submissions scraped\n",
    "    total_submissions = 0\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num in range(1, max_pages + 1):\n",
    "        log_message(f\"\\n==== Processing Page {page_num}/{max_pages} ====\")\n",
    "        \n",
    "        # Save a page progress file to enable resuming if needed\n",
    "        with open(os.path.join(output_dir, \"page_progress.txt\"), \"w\") as f:\n",
    "            f.write(f\"last_page_started: {page_num}\\n\")\n",
    "        \n",
    "        # Find all view buttons on the current page\n",
    "        try:\n",
    "            # Wait for page to fully load with sufficient timeout\n",
    "            time.sleep(3)  # Initial pause to let page elements settle\n",
    "            \n",
    "            view_buttons = WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a.view-results\"))\n",
    "            )\n",
    "            log_message(f\"Found {len(view_buttons)} 'View' buttons on page {page_num}\")\n",
    "            \n",
    "            # Store the main window handle\n",
    "            main_window = driver.current_window_handle\n",
    "            \n",
    "            # Process submissions in smaller batches to manage memory\n",
    "            page_submissions = []\n",
    "            for batch_start in range(0, len(view_buttons), batch_size):\n",
    "                batch_end = min(batch_start + batch_size, len(view_buttons))\n",
    "                batch_buttons = view_buttons[batch_start:batch_end]\n",
    "                \n",
    "                log_message(f\"Processing batch {batch_start//batch_size + 1} of {(len(view_buttons) + batch_size - 1)//batch_size}\")\n",
    "                \n",
    "                # Open each submission in this batch in a new tab\n",
    "                for i, button in enumerate(batch_buttons):\n",
    "                    try:\n",
    "                        url = button.get_attribute(\"href\")\n",
    "                        submission_id = url.split(\"/code/\")[1] if \"/code/\" in url else \"unknown\"\n",
    "                        \n",
    "                        # Open in new tab using JavaScript\n",
    "                        driver.execute_script(\"arguments[0].setAttribute('target', '_blank');\", button)\n",
    "                        button.click()\n",
    "                        time.sleep(1)  # Pause between opening tabs\n",
    "                        log_message(f\"Opened submission {batch_start + i + 1}/{len(view_buttons)} (ID: {submission_id})\")\n",
    "                    except Exception as e:\n",
    "                        log_message(f\"Error opening tab for submission {batch_start + i + 1}: {e}\")\n",
    "                \n",
    "                # Wait for all tabs to finish loading\n",
    "                time.sleep(5)  # Give time for tabs to start loading\n",
    "                \n",
    "                # Get all window handles (tabs)\n",
    "                all_tabs = driver.window_handles\n",
    "                submission_tabs = [tab for tab in all_tabs if tab != main_window]\n",
    "                \n",
    "                # Process each submission tab in this batch\n",
    "                for tab in submission_tabs:\n",
    "                    try:\n",
    "                        # Switch to the tab\n",
    "                        driver.switch_to.window(tab)\n",
    "                        \n",
    "                        # Wait for the code container to load with a generous timeout\n",
    "                        WebDriverWait(driver, 20).until(\n",
    "                            EC.presence_of_element_located((By.CSS_SELECTOR, \"div.CodeMirror-lines[role='presentation']\"))\n",
    "                        )\n",
    "                        \n",
    "                        # Extract submission details\n",
    "                        current_url = driver.current_url\n",
    "                        submission_id = current_url.split(\"/code/\")[1] if \"/code/\" in current_url else \"unknown\"\n",
    "                        \n",
    "                        # Try multiple selectors for username\n",
    "                        username = \"unknown\"\n",
    "                        for selector in [\".submitter-details .username\", \".profile-username\", \".submitter-name\"]:\n",
    "                            try:\n",
    "                                username_element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                                if username_element.text:\n",
    "                                    username = username_element.text\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "                        \n",
    "                        # Try multiple selectors for problem name\n",
    "                        problem_name = \"unknown\"\n",
    "                        for selector in [\".problem-title\", \".challenge-name\", \".challenge-title\"]:\n",
    "                            try:\n",
    "                                problem_element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                                if problem_element.text:\n",
    "                                    problem_name = problem_element.text\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "                        \n",
    "                        # Try multiple selectors for language\n",
    "                        language = \"unknown\"\n",
    "                        for selector in [\".language-name\", \".select-language\", \".language-selector\"]:\n",
    "                            try:\n",
    "                                language_element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                                if language_element.text:\n",
    "                                    language = language_element.text\n",
    "                                    break\n",
    "                            except:\n",
    "                                continue\n",
    "                        \n",
    "                        # Extract the code\n",
    "                        code_container = driver.find_element(By.CSS_SELECTOR, \"div.CodeMirror-lines[role='presentation']\")\n",
    "                        code_content = code_container.text\n",
    "                        \n",
    "                        # Add data to batch\n",
    "                        submission_data = {\n",
    "                            \"submission_id\": submission_id,\n",
    "                            \"username\": username,\n",
    "                            \"problem_name\": problem_name,\n",
    "                            \"language\": language,\n",
    "                            \"code\": code_content,\n",
    "                            \"page\": page_num,\n",
    "                            \"url\": current_url\n",
    "                        }\n",
    "                        \n",
    "                        page_submissions.append(submission_data)\n",
    "                        log_message(f\"Successfully extracted submission {submission_id}\")\n",
    "                        \n",
    "                        # Close the tab after processing to free memory\n",
    "                        driver.close()\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        log_message(f\"Error processing submission: {e}\")\n",
    "                        try:\n",
    "                            # Take screenshot on error for debugging\n",
    "                            driver.save_screenshot(os.path.join(output_dir, f\"error_page{page_num}_batch{batch_start//batch_size + 1}.png\"))\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        # Close the tab even if there was an error\n",
    "                        try:\n",
    "                            driver.close()\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # Switch back to the main window after processing the batch\n",
    "                driver.switch_to.window(main_window)\n",
    "                \n",
    "                # Short break between batches\n",
    "                time.sleep(3)\n",
    "            \n",
    "            # Save the results for this page\n",
    "            if page_submissions:\n",
    "                total_submissions += len(page_submissions)\n",
    "                page_csv_path = os.path.join(output_dir, f\"hackerrank_submissions_page{page_num:03d}.csv\")\n",
    "                save_to_csv(page_submissions, page_csv_path)\n",
    "                log_message(f\"Saved {len(page_submissions)} submissions from page {page_num}\")\n",
    "            \n",
    "            # Prepare for next page\n",
    "            if page_num < max_pages:\n",
    "                # Random wait between pages to avoid detection\n",
    "                wait_time = random.uniform(wait_between_pages[0], wait_between_pages[1])\n",
    "                log_message(f\"Waiting {wait_time:.1f} seconds before navigating to the next page\")\n",
    "                time.sleep(wait_time)\n",
    "                \n",
    "                # Try to find and click the next page button - UPDATED SELECTOR\n",
    "                try:\n",
    "                    # Look for the link to the next page based on the current page number\n",
    "                    current_page = page_num\n",
    "                    next_page = current_page + 1\n",
    "                    next_button = WebDriverWait(driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, f\"a.backbone[data-page='{next_page}']\"))\n",
    "                    )\n",
    "                    next_button.click()\n",
    "                    log_message(f\"Navigating to page {page_num + 1}\")\n",
    "                    time.sleep(5)  # Wait for next page to load\n",
    "                except (TimeoutException, NoSuchElementException) as e:\n",
    "                    log_message(f\"Error navigating to next page: {e}\")\n",
    "                    break\n",
    "        \n",
    "        except Exception as e:\n",
    "            log_message(f\"Error processing page {page_num}: {e}\")\n",
    "            # Try to recover and continue\n",
    "            try:\n",
    "                driver.refresh()\n",
    "                time.sleep(5)\n",
    "                log_message(\"Page refreshed. Trying to continue...\")\n",
    "            except:\n",
    "                log_message(\"Could not recover. Stopping scraper.\")\n",
    "                break\n",
    "    \n",
    "    # Create a combined CSV of all pages at the end\n",
    "    combine_csv_files(output_dir)\n",
    "    \n",
    "    log_message(f\"Scraping complete! Total submissions scraped: {total_submissions}\")\n",
    "    return total_submissions\n",
    "\n",
    "def save_to_csv(data, filename):\n",
    "    \"\"\"Save scraped data to a CSV file\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as file:\n",
    "            # Define CSV columns\n",
    "            fieldnames = [\"submission_id\", \"username\", \"problem_name\", \"language\", \"code\", \"page\", \"url\"]\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            \n",
    "            # Write header and data\n",
    "            writer.writeheader()\n",
    "            writer.writerows(data)\n",
    "        \n",
    "        print(f\"Successfully saved {len(data)} submissions to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV file {filename}: {e}\")\n",
    "\n",
    "def combine_csv_files(directory, output_file=\"all_submissions.csv\"):\n",
    "    \"\"\"Combine all individual page CSV files into one master file\"\"\"\n",
    "    all_data = []\n",
    "    csv_files = [f for f in os.listdir(directory) if f.startswith(\"hackerrank_submissions_page\") and f.endswith(\".csv\")]\n",
    "    \n",
    "    for csv_file in sorted(csv_files):\n",
    "        file_path = os.path.join(directory, csv_file)\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                all_data.extend(list(reader))\n",
    "            print(f\"Added data from {csv_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csv_file}: {e}\")\n",
    "    \n",
    "    if all_data:\n",
    "        output_path = os.path.join(directory, output_file)\n",
    "        with open(output_path, 'w', newline='', encoding='utf-8') as file:\n",
    "            fieldnames = list(all_data[0].keys())\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(all_data)\n",
    "        print(f\"Successfully combined {len(csv_files)} files into {output_file} with {len(all_data)} total submissions\")\n",
    "    else:\n",
    "        print(\"No data found to combine\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the WebDriver (if running as script)\n",
    "    # options = webdriver.ChromeOptions()\n",
    "    # driver = webdriver.Chrome(options=options)\n",
    "    # driver.get(\"https://www.hackerrank.com/contests/tcet-shastra-coding-contest-13-a/judge/submissions/2\")\n",
    "    \n",
    "    # Run the scraper with existing driver\n",
    "    scrape_hackerrank_with_pagination(\n",
    "        driver=driver,\n",
    "        max_pages=190,              # Adjust as needed (190 pages total)\n",
    "        batch_size=3,               # Process 3 submissions at a time\n",
    "        output_dir=\"hackerrank_data\",\n",
    "        wait_between_pages=(5,8)  # Random wait between pages\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T07:44:48.758843500Z",
     "start_time": "2025-04-06T07:26:16.090106600Z"
    }
   },
   "id": "3bf8271f2291ed9e",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: hackerrank_data\\all_submissions.csv does not exist\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def clean_code_section(code_text):\n",
    "    \"\"\"\n",
    "    Clean code by removing standalone line numbers.\n",
    "    The code format has line numbers as separate lines:\n",
    "    1\n",
    "    import java.util.Scanner;\n",
    "    2\n",
    "    3\n",
    "    \"\"\"\n",
    "    if pd.isna(code_text) or code_text == '':\n",
    "        return ''\n",
    "        \n",
    "    lines = code_text.split('\\n')\n",
    "    cleaned_lines = []\n",
    "    \n",
    "    # Regex to match lines that contain only numbers (possibly with whitespace)\n",
    "    standalone_number_pattern = re.compile(r'^\\s*\\d+\\s*$')\n",
    "    \n",
    "    for line in lines:\n",
    "        # Skip lines that are just numbers\n",
    "        if not standalone_number_pattern.match(line):\n",
    "            cleaned_lines.append(line)\n",
    "    \n",
    "    # Print a small sample for debugging\n",
    "    print(\"\\nCleaning example:\")\n",
    "    print(\"BEFORE (first few lines):\")\n",
    "    for i in range(min(5, len(lines))):\n",
    "        print(f\"  {lines[i]}\")\n",
    "    \n",
    "    print(\"\\nAFTER (first few lines):\")\n",
    "    for i in range(min(5, len(cleaned_lines))):\n",
    "        print(f\"  {cleaned_lines[i]}\")\n",
    "    \n",
    "    return '\\n'.join(cleaned_lines)\n",
    "\n",
    "def process_csv_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process a CSV file containing HackerRank submissions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Reading {input_file}...\")\n",
    "        df = pd.read_csv(input_file, encoding='utf-8')\n",
    "        \n",
    "        if 'code' not in df.columns:\n",
    "            print(f\"Error: 'code' column not found in {input_file}\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"Cleaning {len(df)} code submissions in {os.path.basename(input_file)}...\")\n",
    "        \n",
    "        # Process a sample first to verify\n",
    "        if not df.empty:\n",
    "            sample_index = 0\n",
    "            sample_orig = df.iloc[sample_index]['code']\n",
    "            cleaned_sample = clean_code_section(sample_orig)\n",
    "            \n",
    "            # Save samples for verification\n",
    "            output_dir = os.path.dirname(output_file)\n",
    "            with open(os.path.join(output_dir, \"sample_original.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(sample_orig)\n",
    "            with open(os.path.join(output_dir, \"sample_cleaned.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(cleaned_sample)\n",
    "            \n",
    "            print(\"\\nSaved sample files for verification\")\n",
    "        \n",
    "        # Clean all code entries\n",
    "        df['code'] = df['code'].apply(clean_code_section)\n",
    "        \n",
    "        # Save the cleaned data\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "        print(f\"Successfully saved cleaned data to {output_file}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Directory paths\n",
    "    INPUT_DIR = \"hackerrank_data\"\n",
    "    OUTPUT_DIR = \"hackerrank_data_cleaned\"\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        print(f\"Created output directory: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # Process the all_submissions.csv file\n",
    "    input_path = os.path.join(INPUT_DIR, \"all_submissions.csv\")\n",
    "    output_path = os.path.join(OUTPUT_DIR, \"cleaned_all_submissions.csv\")\n",
    "    \n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"Error: {input_path} does not exist\")\n",
    "        return\n",
    "    \n",
    "    process_csv_file(input_path, output_path)\n",
    "    \n",
    "    print(\"\\nVerification:\")\n",
    "    if os.path.exists(output_path):\n",
    "        orig_df = pd.read_csv(input_path)\n",
    "        cleaned_df = pd.read_csv(output_path)\n",
    "        print(f\"Original rows: {len(orig_df)}\")\n",
    "        print(f\"Cleaned rows: {len(cleaned_df)}\")\n",
    "        print(\"Cleaning complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T15:03:46.998279800Z",
     "start_time": "2025-04-09T15:03:46.287925300Z"
    }
   },
   "id": "efdb110f055ad0c9",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: hackerrank_data_cleaned\\cleaned_all_submissions.csv does not exist\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def detect_plagiarism(csv_file, output_dir=\"plagiarism_results\"):\n",
    "    \"\"\"\n",
    "    Detect plagiarism by finding identical code across different submission IDs.\n",
    "    \n",
    "    Args:\n",
    "        csv_file: Path to the cleaned CSV file with submissions\n",
    "        output_dir: Directory to save plagiarism results\n",
    "    \"\"\"\n",
    "    print(f\"Reading submissions from {csv_file}...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    if 'code' not in df.columns or 'submission_id' not in df.columns:\n",
    "        print(\"Error: CSV must contain 'code' and 'submission_id' columns\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing {len(df)} submissions for plagiarism...\")\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Step 1: Group by problem to compare only within the same problem\n",
    "    if 'problem_name' in df.columns:\n",
    "        print(\"Grouping submissions by problem name...\")\n",
    "        problem_groups = df.groupby('problem_name')\n",
    "    else:\n",
    "        # If no problem_name column, treat all submissions as one group\n",
    "        print(\"No problem_name column found, comparing all submissions together\")\n",
    "        problem_groups = [(\"all_problems\", df)]\n",
    "    \n",
    "    # Step 2: Find identical code within each problem\n",
    "    results = []\n",
    "    all_plagiarism_groups = []\n",
    "    \n",
    "    # Process each problem group\n",
    "    for problem_name, group_df in tqdm(problem_groups):\n",
    "        # Hash the code to find duplicates efficiently\n",
    "        code_hash_to_submissions = defaultdict(list)\n",
    "        \n",
    "        # Process each submission in the group\n",
    "        for _, row in group_df.iterrows():\n",
    "            submission_id = row['submission_id']\n",
    "            code = row['code']\n",
    "            username = row.get('username', 'unknown')\n",
    "            language = row.get('language', 'unknown')\n",
    "            \n",
    "            # Skip empty code\n",
    "            if pd.isna(code) or code.strip() == '':\n",
    "                continue\n",
    "                \n",
    "            # Normalize code by removing whitespace to catch minor formatting differences\n",
    "            normalized_code = '\\n'.join([line.strip() for line in code.split('\\n') if line.strip()])\n",
    "            \n",
    "            # Hash the normalized code\n",
    "            code_hash = hashlib.md5(normalized_code.encode()).hexdigest()\n",
    "            \n",
    "            # Store submission details\n",
    "            code_hash_to_submissions[code_hash].append({\n",
    "                'submission_id': submission_id,\n",
    "                'username': username,\n",
    "                'language': language\n",
    "            })\n",
    "        \n",
    "        # Find groups with multiple submissions (potential plagiarism)\n",
    "        plagiarism_groups = {\n",
    "            code_hash: submissions for code_hash, submissions in code_hash_to_submissions.items()\n",
    "            if len(submissions) > 1\n",
    "        }\n",
    "        \n",
    "        if plagiarism_groups:\n",
    "            # Get the original code for each group\n",
    "            for code_hash, submissions in plagiarism_groups.items():\n",
    "                # Find the code for this hash\n",
    "                for _, row in group_df.iterrows():\n",
    "                    code = row['code']\n",
    "                    if pd.isna(code) or code.strip() == '':\n",
    "                        continue\n",
    "                        \n",
    "                    normalized_code = '\\n'.join([line.strip() for line in code.split('\\n') if line.strip()])\n",
    "                    if hashlib.md5(normalized_code.encode()).hexdigest() == code_hash:\n",
    "                        # Found a match, add code to the group and break\n",
    "                        plagiarism_group = {\n",
    "                            'problem_name': problem_name,\n",
    "                            'submissions': submissions,\n",
    "                            'identical_submissions_count': len(submissions),\n",
    "                            'code': code\n",
    "                        }\n",
    "                        all_plagiarism_groups.append(plagiarism_group)\n",
    "                        break\n",
    "            \n",
    "            # Record summary for this problem\n",
    "            results.append({\n",
    "                'problem_name': problem_name,\n",
    "                'total_submissions': len(group_df),\n",
    "                'plagiarism_groups': len(plagiarism_groups),\n",
    "                'total_plagiarized_submissions': sum(len(subs) for subs in plagiarism_groups.values())\n",
    "            })\n",
    "    \n",
    "    # Step 3: Generate reports\n",
    "    # Summary report\n",
    "    summary_df = pd.DataFrame(results)\n",
    "    summary_file = os.path.join(output_dir, \"plagiarism_summary.csv\")\n",
    "    summary_df.to_csv(summary_file, index=False)\n",
    "    print(f\"Summary report saved to {summary_file}\")\n",
    "    \n",
    "    # Detailed report with all plagiarism groups\n",
    "    detailed_file = os.path.join(output_dir, \"plagiarism_detailed.txt\")\n",
    "    with open(detailed_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"DETAILED PLAGIARISM REPORT\\n\")\n",
    "        f.write(\"=========================\\n\\n\")\n",
    "        \n",
    "        for i, group in enumerate(sorted(all_plagiarism_groups, key=lambda x: x['identical_submissions_count'], reverse=True)):\n",
    "            f.write(f\"Group {i+1}: {group['problem_name']} - {group['identical_submissions_count']} identical submissions\\n\")\n",
    "            \n",
    "            # Write submission details\n",
    "            f.write(\"Submissions:\\n\")\n",
    "            for sub in group['submissions']:\n",
    "                f.write(f\"  - ID: {sub['submission_id']}, User: {sub['username']}, Language: {sub['language']}\\n\")\n",
    "            \n",
    "            # Write code sample\n",
    "            f.write(\"\\nCode:\\n\")\n",
    "            f.write(\"```\\n\")\n",
    "            f.write(group['code'][:500])  # First 500 chars\n",
    "            if len(group['code']) > 500:\n",
    "                f.write(\"\\n... (truncated) ...\\n\")\n",
    "            else:\n",
    "                f.write(\"\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"Detailed report saved to {detailed_file}\")\n",
    "    \n",
    "    # Export each plagiarism group to a separate CSV for easy analysis\n",
    "    export_df_rows = []\n",
    "    for group_index, group in enumerate(all_plagiarism_groups):\n",
    "        problem_name = group['problem_name']\n",
    "        for sub in group['submissions']:\n",
    "            export_df_rows.append({\n",
    "                'group_id': group_index + 1,\n",
    "                'problem_name': problem_name,\n",
    "                'submission_id': sub['submission_id'],\n",
    "                'username': sub['username'],\n",
    "                'language': sub['language'],\n",
    "                'identical_submissions_in_group': len(group['submissions'])\n",
    "            })\n",
    "    \n",
    "    export_df = pd.DataFrame(export_df_rows)\n",
    "    export_file = os.path.join(output_dir, \"plagiarism_groups.csv\")\n",
    "    export_df.to_csv(export_file, index=False)\n",
    "    print(f\"Plagiarism groups exported to {export_file}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_plagiarism_groups = len(all_plagiarism_groups)\n",
    "    total_plagiarized_submissions = sum(len(group['submissions']) for group in all_plagiarism_groups)\n",
    "    \n",
    "    print(\"\\nPlagiarism Detection Results:\")\n",
    "    print(f\"- Total submissions analyzed: {len(df)}\")\n",
    "    print(f\"- Plagiarism groups found: {total_plagiarism_groups}\")\n",
    "    print(f\"- Submissions involved in plagiarism: {total_plagiarized_submissions}\")\n",
    "    \n",
    "    if total_plagiarism_groups > 0:\n",
    "        # Find the largest plagiarism group\n",
    "        largest_group = max(all_plagiarism_groups, key=lambda x: x['identical_submissions_count'])\n",
    "        print(f\"- Largest plagiarism group: {largest_group['identical_submissions_count']} identical submissions \" +\n",
    "              f\"for problem '{largest_group['problem_name']}'\")\n",
    "    \n",
    "    return export_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Directory paths\n",
    "    INPUT_DIR = \"hackerrank_data_cleaned\"\n",
    "    OUTPUT_DIR = \"plagiarism_results\"\n",
    "    \n",
    "    # Input file (cleaned submissions)\n",
    "    input_file = os.path.join(INPUT_DIR, \"cleaned_all_submissions.csv\")\n",
    "    \n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"Error: {input_file} does not exist\")\n",
    "    else:\n",
    "        detect_plagiarism(input_file, OUTPUT_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T15:04:27.539262900Z",
     "start_time": "2025-04-09T15:04:27.528658700Z"
    }
   },
   "id": "89c04064315d2314",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e1d3ac550b000eb3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34b548cb6cb5ac56"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
